import pandas as pd
from arch.unitroot import ADF
import statsmodels.api as sm
from scipy import stats
from scipy.stats import norm
import numpy as np
from statsmodels.tsa.stattools import adfuller

class UnitRootTests:
    def __init__(self, df):
        """
        Initialize the UnitRootTests class.

        Parameters:
        - df: Pandas DataFrame
            The input DataFrame containing the time series data.
        -pval: float, optional
            The desired significance level    
        """
        self.df = df
        self.T = len(df)
        
        
    def tau_tau(self, critical_value=-3.45):
        """
        Model (c): constant and deterministic trend
        H0) \gamma = 0
        
        The ττ statistic: Constant + Time Trend  
        alpha          0.01  0.025  0.05  0.10
        Sample_Size_T
        25            -4.38  -3.95 -3.60 -3.24
        50            -4.15  -3.80 -3.50 -3.18
        100           -4.05  -3.73 -3.45 -3.15
        250           -3.99  -3.69 -3.43 -3.13
        500           -3.97  -3.67 -3.42 -3.13
        ∞             -3.96  -3.67 -3.41 -3.12

        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: -3.45).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()

        for col in self.df.columns:
            adf_c = ADF(self.df[col], trend='ct')
            reg_res_c = adf_c.regression
            tau_tau = reg_res_c.tvalues[0]
            reject_c = tau_tau < critical_value
            if reject_c:
                rh0[col] = self.df[col]
            else:
                no_rh0[col] = self.df[col]
                
        #no_rh0_df = self.df[list(no_rh0.columns)]        

        return rh0, no_rh0
    
    def phi_2(self, critical_value=6.50, r=3, alpha=0.05, cols_norho=None):
        """
        Use phi_2 to test the null hypothesis that the data is generated by model (a)
        against the alternative that model (c) is the 'true' model.
        H0) a_0 = \gamma = a_2 = 0
        
        Dicky Fuller (1981) critical values for Φ_2 are:
                Empirical Distribution of Φ_2  
        alpha          0.01  0.025  0.05  0.10
        Sample_Size_T
        25             4.67   5.68  6.75  8.21
        50             4.31   5.13  5.94  7.02
        100            4.16   4.88  5.59  6.50
        250            4.07   4.75  5.40  6.22
        500            4.05   4.71  5.35  6.15
        ∞              4.03   4.68  5.31  6.09
        
        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: 5.59).
        - r: int, optional
            The number of restrictions in the null hypothesis (default: 3).
        - alpha: float, optional
            The significance level (default: 0.05).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()
        
        if cols_norho is None:
            df_sliced = self.df.columns
        else:
            df_sliced =  self.df[cols_norho]

        for col in df_sliced:
            # model c: unrestricted
            adf_c = ADF(df_sliced[col], trend='ct')
            reg_res_c = adf_c.regression
            SSR_u = reg_res_c.resid.dot(reg_res_c.resid)
            k = len(reg_res_c.params)

            # model a: restricted
            adf_a = ADF(df_sliced[col], trend='n')
            reg_res_a = adf_a.regression
            SSR_r = reg_res_a.resid.dot(reg_res_a.resid)
            phi_2 = ((SSR_r - SSR_u) / r) / (SSR_u / (self.T - k))

            reject_H0 = phi_2 > critical_value
            if reject_H0:
                rh0[col] = df_sliced[col]
            else:
                no_rh0[col] = df_sliced[col]

        return rh0, no_rh0

    def phi_3(self, critical_value=7.44, r=2, alpha=0.05, cols_norho=None):
        """
        Use phi_3 to test the null hypothesis that the data is generated by model (b)
        against the alternative that model (c) is the 'true' model.
        H0) \gamma = a_2 = 0
        
        Dicky Fuller (1981) critical values for Φ_3 are:
            Empirical Distribution of Φ_3 
        alpha          0.01  0.025  0.05   0.10
        Sample_Size_T
        25             5.91   7.24  8.65  10.61
        50             5.61   6.73  7.81   9.31
        100            5.47   6.49  7.44   8.73
        250            5.39   6.34  7.25   8.43
        500            5.36   6.30  7.20   8.34
        ∞              5.34   6.25  7.16   8.27

        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: 7.44).
        - r: int, optional
            The number of restrictions in the null hypothesis (default: 2).
        - alpha: float, optional
            The significance level (default: 0.05).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()
        if cols_norho is None:
            df_sliced = self.df.columns
        else:
            df_sliced =  self.df[cols_norho]

        for col in cols_norho:
            # model c: unrestricted
            adf_c = ADF(df_sliced[col], trend='ct')
            reg_res_c = adf_c.regression
            SSR_u = reg_res_c.resid.dot(reg_res_c.resid)
            k = len(reg_res_c.params)

            # model b: restricted
            adf_b = ADF(df_sliced[col], trend='c')
            reg_res_b = adf_b.regression
            SSR_r = reg_res_b.resid.dot(reg_res_b.resid)
            phi_3 = ((SSR_r - SSR_u) / r) / (SSR_u / (self.T - k))

            reject_H0 = phi_3 > critical_value
            if reject_H0:
                rh0[col] = df_sliced[col]
            else:
                no_rh0[col] = df_sliced[col]

        return rh0, no_rh0

    def tau_mu(self, critical_value=-2.90):
        """
        Model (b): constant but no time trend (a2 = 0)
        H0) \gamma = 0
        The τµ statistic: Constant but No Time Trend (a2 = 0)  
        alpha          0.01  0.025  0.05  0.10
        Sample_Size_T
        25            -3.75  -3.33 -2.99 -2.62
        50            -3.59  -3.22 -2.93 -2.60
        100           -3.50  -3.17 -2.90 -2.59
        250           -3.45  -3.14 -2.88 -2.58
        500           -3.44  -3.13 -2.87 -2.57
        ∞             -3.42  -3.12 -2.86 -2.57

        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: -2.90).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()

        for col in self.df.columns:
            adf_b = ADF(self.df[col], trend='c')
            reg_res_b = adf_b.regression
            tau_mu = reg_res_b.tvalues[0]
            reject_c = tau_mu < critical_value
            if reject_c:
                rh0[col] = self.df[col]
            else:
                no_rh0[col] = self.df[col]

        return rh0, no_rh0

    def phi_1(self, critical_value=5.57, r=2, alpha=0.05, cols_norho=None):
        """
        Use phi_1 to test the null hypothesis that the data is generated by model (a)
        against the alternative that model (b) is the 'true' model.
        H0) \gamma = a_0 = 0

        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: 5.57).
        - r: int, optional
            The number of restrictions in the null hypothesis (default: 2).
        - alpha: float, optional
            The significance level (default: 0.05).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()
        if cols_norho is None:
            df_sliced = self.df.columns
        else:
            df_sliced =  self.df[cols_norho]

        for col in df_sliced:
            # model b: unrestricted
            adf_b = ADF(df_sliced[col], trend='c')
            reg_res_b = adf_b.regression
            SSR_u = reg_res_b.resid.dot(reg_res_b.resid)
            k = len(reg_res_b.params)

            # model a: restricted
            adf_a = ADF(df_sliced[col], trend='n')
            reg_res_a = adf_a.regression
            SSR_r = reg_res_a.resid.dot(reg_res_a.resid)
            phi_1 = ((SSR_r - SSR_u) / r) / (SSR_u / (self.T - k))

            reject_H0 = phi_1 < critical_value
            if reject_H0:
                rh0[col] = df_sliced[col]
            else:
                no_rh0[col] = df_sliced[col]

        return rh0, no_rh0

    def tau(self, critical_value=-1.95):
        """
        Model (a): Constant Only (a1 = 0, a2 = 0)
        H0) \gamma = 0

        Parameters:
        - critical_value: float, optional
            The critical value for hypothesis testing (default: -1.95).

        Returns:
        - rh0: Pandas DataFrame
            The columns that reject the null hypothesis.
        - no_rh0: Pandas DataFrame
            The columns that do not reject the null hypothesis.
        """
        results = {}
        rh0 = pd.DataFrame()
        no_rh0 = pd.DataFrame()

        for col in self.df.columns:
            adf = ADF(self.df[col], trend='n')
            reg_res = adf.regression
            tau = reg_res.tvalues[0]
            reject_c = tau < critical_value
            if reject_c:
                rh0[col] = self.df[col]
            else:
                no_rh0[col] = self.df[col]

        return rh0, no_rh0
    
    def test_a2(self, cols_norho=None):
            """
            Step 2 in Enders procedure for UR testing.
            Perform hypothesis testing for a2 = 0 on each column in the DataFrame.

            Returns:
            - rh_a2_0: Pandas DataFrame
                The columns that reject the null hypothesis a2 = 0.
            - no_rh_a2_0: Pandas DataFrame
                The columns that do not reject the null hypothesis a2 = 0.
            """
            rh_a2_0 = pd.DataFrame()
            no_rh_a2_0 = pd.DataFrame()
            if cols_norho is None:
                df_sliced = self.df.columns
            else:
                df_sliced =  self.df[cols_norho]
            for column in df_sliced:
                # Calculate the suggested upper bound for the number of lags, k
                n = self.T
                k = int(np.trunc((n - 1) ** (1 / 3)))

                # Create lagged variables
                for i in range(1, k + 1):
                    df_sliced[f'{column}_lag{i}'] = df_sliced[column].diff(i)

                # Remove missing values from the DataFrame
                df_cleaned = df_sliced.dropna()

                # Define the dependent variable (Delta_y) and the independent variables (trend and lagged variables)
                y = df_cleaned[column]
                X = df_cleaned[['trend'] + [f'{column}_lag{i}' for i in range(1, k + 1)]]

                # Add a constant term to the independent variables
                X = sm.add_constant(X)

                # Fit the model using ordinary least squares (OLS)
                model = sm.OLS(y, X)
                results = model.fit()

                # Test the hypothesis a2 = 0 using t-distribution
                a2_coef = results.params['trend']
                a2_std_err = results.bse['trend']
                t_statistic = a2_coef / a2_std_err
                degrees_of_freedom = len(results.resid) - len(results.params)
                p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df=degrees_of_freedom))

                # Store the column in the respective DataFrame based on the test result
                if p_value < 0.05:
                    rh_a2_0[column] = df_sliced[column]
                else:
                    no_rh_a2_0[column] = df_sliced[column]

            return rh_a2_0, no_rh_a2_0
        
def adf_test_statsmodels(dataframe):
    print("Results of Dickey-Fuller Test:")
    for column in dataframe.columns:
        print("Column:", column)
        dftest = adfuller(dataframe[column], autolag="AIC")
        dfoutput = pd.Series(
            dftest[0:4],
            index=[
                "Test Statistic",
                "p-value",
                "#Lags Used",
                "Number of Observations Used",
            ],
        )
        for key, value in dftest[4].items():
            dfoutput["Critical Value (%s)" % key] = value
        print(dfoutput)
        print("------------------")        