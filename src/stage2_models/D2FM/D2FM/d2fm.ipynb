{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cd4nMBK48QS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os,sys,inspect\n",
        "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parentdir = os.path.dirname(currentdir)\n",
        "parentdir = os.path.dirname(parentdir)\n",
        "sys.path.insert(0,parentdir)"
      ],
      "metadata": {
        "id": "IUTkX92sKF5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xll83j-0QPuY",
        "outputId": "fa92c5cd-cca7-45ab-e2de-4dec4914e7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/D2FM')\n",
        "module_path = '/content/drive/My Drive/D2FM'\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ],
      "metadata": {
        "id": "OHQp36zkQZ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pykalman"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS3rYn20WLyj",
        "outputId": "c899414c-c55d-436f-da1b-b86206e9d5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.10/dist-packages (0.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import models.ddfm"
      ],
      "metadata": {
        "id": "sfZM6nNNVDp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--U2KPzqary4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from typing import Tuple\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from statsmodels.tsa.statespace.dynamic_factor_mq import DynamicFactorMQ as DFM\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "from pykalman import KalmanFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cgoKGqbd-ea"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk9uMGiReqjf"
      },
      "outputs": [],
      "source": [
        "#from models.ddfm import DDFM\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from typing import Tuple\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5TS6VMnrDrw"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/D2FM/sfr_train.csv')\n",
        "df_test=pd.read_csv('/content/drive/MyDrive/D2FM/sfr_test.csv')\n",
        "df_train_idx=df_train.set_index(\"index\")\n",
        "df_test_idx=df_test.set_index(\"index\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df_train_idx_scaled = scaler.fit_transform(df_train_idx)\n",
        "df_test_idx_scaled= scaler.fit_transform(df_test_idx)"
      ],
      "metadata": {
        "id": "NQySdX1ch0hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_idx.sort_index(inplace=True)\n",
        "mean_test = df_test_idx.mean().values\n",
        "sigma_test = df_test_idx.std().values\n",
        "data_test = (df_test_idx - mean_test ) / sigma_test"
      ],
      "metadata": {
        "id": "YPYE-5uxxcSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@tf.function\n",
        "def mse_missing(y_actual: tf.Tensor, y_predicted: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Custom loss (mse) for missing data.\n",
        "    \"\"\"\n",
        "    mask = tf.where(tf.math.is_nan(y_actual), tf.zeros_like(y_actual), tf.ones_like(y_actual))\n",
        "    y_actual_ = tf.where(tf.math.is_nan(y_actual), tf.zeros_like(y_actual), y_actual)\n",
        "    y_predicted_ = tf.multiply(y_predicted, mask)\n",
        "    return keras.losses.mean_squared_error(y_actual_, y_predicted_)\n",
        "\n",
        "\n",
        "def convergence_checker(y_prev, y_now, y_actual):\n",
        "    # TODO: Consider converting all to tensorflow\n",
        "    loss_minus = mse(y_prev[~np.isnan(y_actual)], y_actual[~np.isnan(y_actual)])\n",
        "    loss = mse(y_now[~np.isnan(y_actual)], y_actual[~np.isnan(y_actual)])\n",
        "    return np.abs(loss - loss_minus) / loss_minus, loss\n",
        "\n",
        "def convert_decoder_to_numpy(decoder: keras.Model, has_bias: bool, factor_oder: int,\n",
        "                             structure_decoder: tuple = None) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Method to convert the decoder (a keras Model) to a numpy object\n",
        "    Args:\n",
        "        decoder: decoder, a keras Model\n",
        "        has_bias: whether there is a bias term\n",
        "        factor_oder: lag order for the common factors\n",
        "        structure_decoder: the structure of the decoder, None for single layer\n",
        "\n",
        "    Returns:\n",
        "        weights and biases\n",
        "    \"\"\"\n",
        "    if structure_decoder is None:\n",
        "        if has_bias:\n",
        "            ws, bs = decoder.get_layer(index=-1).get_weights()\n",
        "        else:\n",
        "            ws = decoder.get_layer(index=-1).get_weights()[0]\n",
        "            bs = np.zeros(ws.shape[1])\n",
        "        # observable equation\n",
        "        if factor_oder == 2:\n",
        "            emission = np.hstack((\n",
        "                # bs.reshape(-1, 1),  # bias term\n",
        "                ws.T,  # weight term\n",
        "                np.zeros((ws.shape[1], ws.shape[0])),  # make zero lagged values\n",
        "                np.identity(ws.shape[1])  # idio\n",
        "            ))\n",
        "        elif factor_oder == 1:\n",
        "            emission = np.hstack((\n",
        "                # bs.reshape(-1, 1),  # bias term\n",
        "                ws.T,  # weight term\n",
        "                np.identity(ws.shape[1])  # idio\n",
        "            ))\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only VAR(2) or VAR(1) for common factors at the moment.\")\n",
        "    else:\n",
        "        NotImplementedError(\"Nonlinear decoder not available yet!\")\n",
        "\n",
        "    return bs, emission\n",
        "\n",
        "\n",
        "def get_transition_params(f_t: np.ndarray, eps_t: np.ndarray, factor_oder: int, bool_no_miss: np.ndarray) -> Tuple[\n",
        "    np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Method to calculate tran\n",
        "    Args:\n",
        "        f_t: common factors\n",
        "        eps_t: idiosyncratic terms\n",
        "        factor_oder: lag order for the common factors\n",
        "        bool_no_miss: array to keep track of non-missing values\n",
        "    Returns:\n",
        "        autoregressive matrix, covariance matrix residuals, unconditional mean, unconditional variance, latent states\n",
        "    \"\"\"\n",
        "    if factor_oder == 2:\n",
        "        f_past = np.hstack((f_t[1:-1, :], f_t[:-2, :]))\n",
        "        A_f = (np.linalg.pinv(f_past.T @ f_past) @ f_past.T @ f_t[2:, :]).T\n",
        "    elif factor_oder == 1:\n",
        "        f_past = f_t[:-1, :]\n",
        "        A_f = (np.linalg.pinv(f_past.T @ f_past) @ f_past.T @ f_t[1:, :]).T\n",
        "    else:\n",
        "        raise NotImplementedError(\"Only VAR(2) or VAR(1) for common factors at the moment.\")\n",
        "    # get AR coeffs. from idiosyncratic\n",
        "    A_eps, _, _ = get_idio(eps_t, bool_no_miss)\n",
        "    # companion form x_t = [1, f_t, f_t_1, eps_t]\n",
        "    if factor_oder == 2:\n",
        "        # x_t = np.vstack((np.ones((1, f_past.shape[0] + 1)), f_t[1:, :].T, f_t[:-1, :].T, eps_t[1:, :].T))\n",
        "        x_t = np.vstack((f_t[1:, :].T, f_t[:-1, :].T, eps_t[1:, :].T))\n",
        "        # A = np.vstack((\n",
        "        #     np.hstack((1, np.zeros(x_t.shape[0] - 1))).reshape(1, -1),  # intercept\n",
        "        #     np.hstack(\n",
        "        #         (np.zeros((A_f.shape[0], 1)), A_f, np.zeros((A_f.shape[0], x_t.shape[0] - 1 - A_f.shape[1])))),\n",
        "        #     # VAR factors\n",
        "        #     np.hstack((np.zeros((A_f.shape[0], 1)), np.identity(A_f.shape[0]),\n",
        "        #                np.zeros((A_f.shape[0], x_t.shape[0] - 1 - A_f.shape[0])))),\n",
        "        #     np.hstack((np.zeros((x_t.shape[0] - (A_f.shape[1] + 1), A_f.shape[1] + 1)), A_eps))  # AR 1 idio\n",
        "        # ))\n",
        "        A = np.vstack((\n",
        "            np.hstack(\n",
        "                (A_f, np.zeros((A_f.shape[0], eps_t.shape[1])))),  # VAR factors\n",
        "            np.hstack((np.identity(A_f.shape[0]), np.zeros((A_f.shape[0], A_f.shape[0] + eps_t.shape[1])))),\n",
        "            np.hstack((np.zeros((eps_t.shape[1], A_f.shape[1])), A_eps))  # AR 1 idio\n",
        "        ))\n",
        "    elif factor_oder == 1:\n",
        "        # x_t = np.vstack((np.ones((1, f_past.shape[0] + 1)), f_t.T, eps_t.T))\n",
        "        x_t = np.vstack((f_t.T, eps_t.T))\n",
        "        # A = np.vstack((\n",
        "        #     np.hstack((1, np.zeros(x_t.shape[0] - 1))).reshape(1, -1),  # intercept\n",
        "        #     np.hstack(\n",
        "        #         (np.zeros((A_f.shape[0], 1)), A_f, np.zeros((A_f.shape[0], x_t.shape[0] - 1 - A_f.shape[1])))),\n",
        "        #     # VAR factors\n",
        "        #     np.hstack((np.zeros((x_t.shape[0] - (A_f.shape[1] + 1), A_f.shape[1] + 1)), A_eps))  # AR 1 idio\n",
        "        # ))\n",
        "        A = np.vstack((\n",
        "            np.hstack((A_f, np.zeros((A_f.shape[0], eps_t.shape[1])))),  # VAR factors\n",
        "            np.hstack((np.zeros((eps_t.shape[1], A_f.shape[1])), A_eps))  # AR 1 idio\n",
        "        ))\n",
        "    else:\n",
        "        raise NotImplementedError(\"\")\n",
        "    # error term matrix\n",
        "    w_t = x_t[:, 1:] - A @ x_t[:, :-1]\n",
        "    W = np.diag(np.diag(np.cov(w_t)))\n",
        "    # Set to unconditional moments of x_0 = [1, f_0, f_0_1, eps_0]\n",
        "    mu_0 = np.mean(x_t, axis=1)\n",
        "    Σ_0 = np.cov(x_t)\n",
        "    # zero correlation with idiosyncratic and diagonal covariance among them\n",
        "    Σ_0[:A_f.shape[1], A_f.shape[1]:] = 0\n",
        "    Σ_0[A_f.shape[1]:, :A_f.shape[1]] = 0\n",
        "    Σ_0[A_f.shape[1]:, A_f.shape[1]:] = np.diag(np.diag(Σ_0[A_f.shape[1]:, A_f.shape[1]:]))\n",
        "    return A, W, mu_0, Σ_0, x_t\n",
        "\n",
        "\n",
        "def get_idio(eps: np.ndarray, idx_no_missings: np.ndarray, min_obs: int = 10) -> Tuple[\n",
        "    np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Method to get AR(1) statistics from eps.\n",
        "    Args:\n",
        "        eps: series of idiosyncratic AR(1)s\n",
        "        idx_no_missings: array to keep track of non-missing values\n",
        "        min_obs: minimum number of observations to estimate the statistics\n",
        "\n",
        "    Returns:\n",
        "        autoregressive coefficients, mean, standard deviation\n",
        "    \"\"\"\n",
        "    # init params statistics\n",
        "    phi = np.zeros((eps.shape[1], eps.shape[1]))\n",
        "    mu_eps = np.zeros(eps.shape[1])\n",
        "    std_eps = np.zeros(eps.shape[1])\n",
        "    # loop over idios\n",
        "    for j in range(eps.shape[1]):\n",
        "        to_select = idx_no_missings[:, j]  # ~np.isnan(self.z_actual[:, j])\n",
        "        to_select = np.hstack((np.array([False]), to_select[:-1] * to_select[1:]))\n",
        "        if np.sum(to_select) > min_obs:\n",
        "            this_eps = eps[to_select, j]\n",
        "        else:\n",
        "            raise ValueError(\"Not enough observation to estimate idio AR(1) parameters.\")\n",
        "            # this_eps = self.eps[:, j]\n",
        "        mu_eps[j] = np.mean(this_eps)\n",
        "        std_eps[j] = np.std(this_eps)\n",
        "        cov1_eps = np.cov(this_eps[1:], this_eps[:-1])[0][1]\n",
        "        phi[j, j] = cov1_eps / (std_eps[j] ** 2)\n",
        "    return phi, mu_eps, std_eps\n"
      ],
      "metadata": {
        "id": "18s2U9c5l7yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel:\n",
        "    \"\"\"\n",
        "    An empty base class for the models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __int__(self, *args, **kwargs):\n",
        "        super().__int__()\n",
        "\n",
        "    def fit(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Fit method.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def predict(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Predict method\n",
        "        \"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "G58sDMfWl0i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateSpace(BaseModel):\n",
        "    \"\"\"\n",
        "    Base class for state-space models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean_z: np.ndarray, sigma_z: np.ndarray, transition_params: dict, measurement_params: dict,\n",
        "                 filter_type: str = \"KalmanFilter\"):\n",
        "        \"\"\"\n",
        "        The init method will build the state space model according to the selected filter.\n",
        "        Args:\n",
        "            mean_z: mean of the measurement variable\n",
        "            sigma_z: standard deviation of the measurement variable\n",
        "            transition_params: parameters of the transition equation\n",
        "            measurement_params: parameters of the measurement equation\n",
        "            filter_type: the type of filter selected\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.mean_z = mean_z\n",
        "        self.sigma_z = sigma_z\n",
        "        # init parameters of the state space to None\n",
        "        self.H = None\n",
        "        self.R = None\n",
        "        self.F = None\n",
        "        self.Q = None\n",
        "        self.predict = None\n",
        "        self.filter = None\n",
        "        if filter_type == \"KalmanFilter\":\n",
        "            # build a linear gaussian state-space model\n",
        "            self.build_lgss(transition_params, measurement_params)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only KalmanFilter is implemented at the moment.\")\n",
        "\n",
        "    def build_lgss(self, transition_params: dict, measurement_params: dict) -> None:\n",
        "        \"\"\"\n",
        "        This method builds a linear gaussian state space model of the following form:\n",
        "            measurement: z_t = H x_t + v_t; v_t ∼ N(0, R)\n",
        "            transition: x_t = F x_t-1 + w_t; w_t ∼ N(0, Q)\n",
        "        Args:\n",
        "            transition_params: parameters of the transition equation\n",
        "            measurement_params: parameters of the measurement equation\n",
        "\n",
        "        Returns:\n",
        "            None, it updates the class attributes.\n",
        "        \"\"\"\n",
        "\n",
        "        self.H, self.R = measurement_params[\"H\"], measurement_params[\"R\"]\n",
        "        self.F, self.Q = transition_params[\"F\"], transition_params[\"Q\"]\n",
        "        self.filter_predict = KalmanFilter(transition_matrices=self.F, observation_matrices=self.H,\n",
        "                                           transition_covariance=self.Q, observation_covariance=self.R)\n",
        "        self.predict = self.predict_lgss\n",
        "        self.filter = self.kalman_filter\n",
        "\n",
        "\n",
        "    def kalman_filter(self, z: np.ndarray, standardize=False, do_em: bool = False) -> Tuple[\n",
        "        np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        This method implements the Kalman Filter.\n",
        "            measurement: z_t = H x_t + v_t; v_t ∼ N(0, R)\n",
        "            transition: x_t = F x_t-1 + w_t; w_t ∼ N(0, Q)\n",
        "        Args:\n",
        "            z: observable realised values\n",
        "            standardize: whether to standardize the inputs or not\n",
        "\n",
        "        Returns:\n",
        "            filtered states and variance-covariance matrix\n",
        "        \"\"\"\n",
        "        z_cpy = z.copy()\n",
        "        if standardize:\n",
        "            z_cpy = (z_cpy - self.mean_z) / self.sigma_z\n",
        "        # make dimensions consistent\n",
        "        if z_cpy.ndim == 1:\n",
        "            z_cpy = np.reshape(z_cpy, (1, z_cpy.shape[0]))\n",
        "        z_cpy = np.ma.array(z_cpy)\n",
        "        z_cpy[np.isnan(z_cpy)] = np.ma.masked\n",
        "        if do_em:\n",
        "            (filtered_state_means, filtered_state_covariances) = self.filter_predict.em(z_cpy).filter(z_cpy)\n",
        "        else:\n",
        "            (filtered_state_means, filtered_state_covariances) = self.filter_predict.filter(z_cpy)\n",
        "        return filtered_state_means, filtered_state_covariances\n",
        "\n",
        "\n",
        "    def predict_lgss(self, x_hat_start: np.ndarray, sigma_x_hat_start: np.ndarray, steps_ahead: int = 1) -> dict:\n",
        "        x_hat = x_hat_start\n",
        "        sigma_x_hat = sigma_x_hat_start\n",
        "        predicted_states = []\n",
        "        #predicted_covariances = []\n",
        "        for _ in range(steps_ahead):\n",
        "          # Predict the next state\n",
        "          x_hat_next = self.F @x_hat\n",
        "          #sigma_x_hat_next = self.state_space_dict[\"transition\"][\"F\"] @ sigma_x_hat @ self.state_space_dict[\"transition\"][\"F\"].T + self.Q\n",
        "          # Store the predictions\n",
        "          predicted_states.append(x_hat_next)\n",
        "          #predicted_covariances.append(sigma_x_hat_next)\n",
        "          # Update current state and covariance for next iteration\n",
        "          x_hat = x_hat_next\n",
        "          #sigma_x_hat = sigma_x_hat_next\n",
        "        #return {\"states\": np.array(predicted_states), \"covariances\": np.array(predicted_covariances)}\n",
        "        return {\"states\": np.array(predicted_states)}\n",
        "\n",
        "    def predict_measurement(self, future_states: np.ndarray) -> np.ndarray:\n",
        "      \"\"\"\n",
        "      Predicts future observations given future states.\n",
        "      Args:\n",
        "        future_states: Future states (f_{t+k}) estimated by the state-space model.\n",
        "      Returns:\n",
        "        Predicted future observations (y_{t+k}).\n",
        "      \"\"\"\n",
        "      predicted_observations = self.H @ future_states.T\n",
        "      return predicted_observations.T"
      ],
      "metadata": {
        "id": "6OltV-bzlsOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(ddfm6.filter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyguBhtIQ3_j",
        "outputId": "821d8b6a-ca84-49de-ed4a-2e1ecb057465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__func__',\n",
              " '__ge__',\n",
              " '__get__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__self__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(ddfm6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zu2dZB_Qpro",
        "outputId": "5467199b-6ecf-425a-cfa8-af7fed523bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__int__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'autoencoder',\n",
              " 'batch_norm',\n",
              " 'batch_size',\n",
              " 'bool_miss',\n",
              " 'bool_no_miss',\n",
              " 'build_inputs',\n",
              " 'build_model',\n",
              " 'build_state_space',\n",
              " 'data',\n",
              " 'data_mod',\n",
              " 'data_mod_only_miss',\n",
              " 'data_tmp',\n",
              " 'decoder',\n",
              " 'disp',\n",
              " 'encoder',\n",
              " 'epoch',\n",
              " 'eps',\n",
              " 'factor_oder',\n",
              " 'factors',\n",
              " 'factors_filtered',\n",
              " 'filter',\n",
              " 'filter_type',\n",
              " 'fit',\n",
              " 'initializer',\n",
              " 'lags_input',\n",
              " 'latents',\n",
              " 'link',\n",
              " 'loss_now',\n",
              " 'max_iter',\n",
              " 'mean_z',\n",
              " 'optimizer',\n",
              " 'pre_train',\n",
              " 'predict',\n",
              " 'predict_observations',\n",
              " 'rng',\n",
              " 'sigma_z',\n",
              " 'state_space',\n",
              " 'state_space_dict',\n",
              " 'structure_decoder',\n",
              " 'structure_encoder',\n",
              " 'tolerance',\n",
              " 'train',\n",
              " 'use_bias',\n",
              " 'z_actual']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.mean_z.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB1KksSwSxNq",
        "outputId": "c1ed30e8-4355-42a9-9bdf-4f31c3a6194a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118,)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.factors_filtered.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGDctrgnRlWa",
        "outputId": "6c4712c6-c078-4fd5-e500-e502ff0fd7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(577, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.state_space_dict[\"measurement\"][\"R\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-AIsUrKQI_1",
        "outputId": "279f2c12-b703-4d94-d6b7-848b551faf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118, 118)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.state_space_dict[\"transition\"][\"Q\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LKI-U-rYNOH",
        "outputId": "43973b9d-40d9-46f3-b18d-81fe9f9c81e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.state_space_dict[\"transition\"][\"F\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3XojRAuJMRd",
        "outputId": "627509f5-ccc9-4c68-81c3-95e7c8e8cbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6.state_space_dict[\"measurement\"][\"H\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhVJycBzIY6B",
        "outputId": "5c9698a5-029b-44da-cc62-755005ff2748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VaRlW_7ivpPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DDFM(BaseModel):\n",
        "    \"\"\"\n",
        "    A class implementing Deep Dynamic Factor Models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: pd.DataFrame, lags_input: int = 0, structure_encoder: tuple = (16, 4),\n",
        "                 structure_decoder: tuple = None, use_bias: bool = True, factor_oder: int = 2, seed: int = 3,\n",
        "                 batch_norm: bool = True, link: str = 'relu', learning_rate: float = 0.005,\n",
        "                 optimizer: str = 'Adam', decay_learning_rate: bool = True,\n",
        "                 epochs: int = 100, batch_size: int = 100, max_iter=200, tolerance: float = 0.0005,\n",
        "                 disp: int = 10):\n",
        "        \"\"\"\n",
        "\n",
        "        Args:\n",
        "            data: input data used for model training\n",
        "            lags_input: number of lags of the inputs on the encoder (default is 0, i.e. same inputs and outputs)\n",
        "            structure_encoder: number of layers and neurons for the encoder\n",
        "            structure_decoder: number of layers and neurons for the decoder (default is None, i.e. asymmetric\n",
        "                autoencoder with one single decoder linear layer)\n",
        "            use_bias: whether to use bias term in the last decoder layer\n",
        "            factor_oder: number of lags in the transition equation for the dynamics of the common factors\n",
        "            seed: seed to control randomness for replicability\n",
        "            batch_norm: whether to add batch norm layers into the encoder\n",
        "            link: the type of link/activation function\n",
        "            learning_rate: the learning rate for the optimizer\n",
        "            optimizer: the selected optimizer\n",
        "            decay_learning_rate: whether to use a decaying learning rate\n",
        "            epochs: number of epochs between MCMC iterations\n",
        "            batch_size: the size of the batch\n",
        "            max_iter: maximum number of iterations for the MCMC\n",
        "            tolerance: the tolerance to stop iterations\n",
        "            disp: display intermediate results every \"disp\" iterations of MCMC\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # common factors\n",
        "        self.factor_oder = factor_oder\n",
        "        if factor_oder not in [1, 2]:\n",
        "            raise ValueError('factor_oder must be 1 or 2')\n",
        "        # z is the observable\n",
        "        print(\"@Info - Note: Sorting data.\")\n",
        "        data.sort_index(inplace=True)\n",
        "        self.mean_z = data.mean().values\n",
        "        self.sigma_z = data.std().values\n",
        "        self.data = (data - self.mean_z) / self.sigma_z\n",
        "        # keep track of the missings locations\n",
        "        self.bool_miss = self.data.isnull()[lags_input:].values\n",
        "        self.bool_no_miss = self.bool_miss == False\n",
        "        # create copies of the original data (needed for training and pre-training)\n",
        "        self.data_mod_only_miss, self.data_mod, self.data_tmp = self.data.copy(), self.data.copy(), self.data.copy()\n",
        "        self.z_actual = self.data[lags_input:].values\n",
        "        # autoencoder structure\n",
        "        self.lags_input = lags_input\n",
        "        self.structure_encoder = structure_encoder\n",
        "        self.structure_decoder = structure_decoder\n",
        "        self.use_bias = use_bias\n",
        "        self.batch_norm = batch_norm\n",
        "        self.link = link\n",
        "        # self.start_quarterly = start_quarterly\n",
        "        if self.structure_decoder is None:\n",
        "            self.filter_type = \"KalmanFilter\"\n",
        "        else:\n",
        "            self.filter_type = \"ToBeDefined\"\n",
        "        # seed setting\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "        self.initializer = tf.keras.initializers.GlorotNormal(seed=seed)\n",
        "        # learning process\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch = epochs\n",
        "        self.max_iter = max_iter\n",
        "        self.tolerance = tolerance\n",
        "        self.disp = disp\n",
        "        # optimizer\n",
        "        if decay_learning_rate:\n",
        "            learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, decay_steps=epochs,\n",
        "                                                                           decay_rate=0.96, staircase=True)\n",
        "        if optimizer == 'SGD':\n",
        "            self.optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "        elif optimizer == 'Adam':\n",
        "            self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        else:\n",
        "            raise KeyError(\"Optimizer must be SGD or Adam\")\n",
        "        # attributes to be populated\n",
        "        self.autoencoder = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.eps = None\n",
        "        self.factors = None\n",
        "        self.factors_filtered = None\n",
        "        self.state_space = None\n",
        "        self.state_space_dict = dict()\n",
        "        self.latents = dict()\n",
        "        self.loss_now=None\n",
        "\n",
        "    def build_inputs(self, interpolate: bool = True) -> None:\n",
        "        \"\"\"\n",
        "        Method to build the inputs of the model from the dataset.\n",
        "        Args:\n",
        "            interpolate: whether to interpolate or not the missing values\n",
        "\n",
        "        Returns:\n",
        "            None, it updates the data attributes of the class\n",
        "        \"\"\"\n",
        "\n",
        "        # create dict with variables and their lagged values\n",
        "        new_dict = {}\n",
        "        for col_name in self.data_mod:\n",
        "            new_dict[col_name] = self.data_mod[col_name]\n",
        "            # create lagged Series\n",
        "            for lag in range(self.lags_input):\n",
        "                new_dict['%s_lag%d' % (col_name, lag + 1)] = self.data_mod[col_name].shift(lag + 1)\n",
        "        # convert to dataframe\n",
        "        self.data_tmp = pd.DataFrame(new_dict, index=self.data_mod.index)\n",
        "        # drop initial nans\n",
        "        self.data_tmp = self.data_tmp[self.lags_input:]\n",
        "        # interpolate\n",
        "        if interpolate and self.data_tmp.isna().sum().sum() > 0:\n",
        "            # self._x_.interpolate(method='spline', limit_direction='forward', inplace=True, order=3)\n",
        "            self.data_tmp.interpolate(method='spline', limit_direction='both', inplace=True, order=3)\n",
        "\n",
        "    def build_model(self) -> None:\n",
        "        \"\"\"\n",
        "        Method to build the keras model.\n",
        "        Returns:\n",
        "            None, it updates the attributes related to the autoencoder.\n",
        "        \"\"\"\n",
        "        # encoder\n",
        "        inputs_ = keras.Input(shape=(int((self.lags_input + 1) * self.data.shape[1]),))\n",
        "        if len(self.structure_encoder) > 1:\n",
        "            encoded = layers.Dense(self.structure_encoder[0], activation=self.link,\n",
        "                                   bias_initializer='zeros', kernel_initializer=self.initializer)(inputs_)\n",
        "            for j in self.structure_encoder[1:]:\n",
        "                if self.batch_norm:\n",
        "                    encoded = layers.BatchNormalization()(encoded)\n",
        "                encoded = layers.Dense(j, activation=self.link,\n",
        "                                       kernel_initializer=self.initializer,\n",
        "                                       bias_initializer='zeros')(encoded)\n",
        "        else:\n",
        "            encoded = layers.Dense(self.structure_encoder[0], bias_initializer='zeros',\n",
        "                                   kernel_initializer=self.initializer)(inputs_)\n",
        "\n",
        "        self.encoder = keras.Model(inputs_, encoded)\n",
        "        # decoder\n",
        "        latent_inputs = keras.Input(shape=(self.structure_encoder[-1],))\n",
        "        if self.structure_decoder:\n",
        "            decoded = layers.Dense(self.structure_decoder[0], activation=self.link,\n",
        "                                   kernel_initializer=self.initializer,\n",
        "                                   bias_initializer='zeros')(latent_inputs)\n",
        "            for j in self.structure_decoder[1:]:\n",
        "                decoded = layers.Dense(j, activation=self.link, kernel_initializer=self.initializer,\n",
        "                                       bias_initializer='zeros')(decoded)\n",
        "            output_ = layers.Dense(self.data.shape[1], bias_initializer='zeros',\n",
        "                                   kernel_initializer=self.initializer, use_bias=self.use_bias)(decoded)\n",
        "        else:\n",
        "            output_ = layers.Dense(self.data.shape[1], bias_initializer='zeros',\n",
        "                                   kernel_initializer=self.initializer, use_bias=self.use_bias)(latent_inputs)\n",
        "        self.decoder = keras.Model(latent_inputs, output_)\n",
        "        outputs_ = self.decoder(self.encoder(inputs_))\n",
        "        # autoencoder\n",
        "        self.autoencoder = keras.Model(inputs_, outputs_)\n",
        "\n",
        "    def pre_train(self, min_obs: int = 50, mult_epoch_pre: int = 1) -> None:\n",
        "        \"\"\"\n",
        "        Method to carry out pre-training of the model.\n",
        "        Args:\n",
        "            min_obs: minimum number of observations for pre-training with no interpolation for missings\n",
        "            mult_epoch_pre: coefficient to be multiplied to number of epochs to deliver to the total number of epochs\n",
        "                for pre-training\n",
        "\n",
        "        Returns:\n",
        "            None, it updates the autoencoders attributes\n",
        "        \"\"\"\n",
        "        # build inputs without interpolation\n",
        "        self.build_inputs(interpolate=False)\n",
        "        # check number of observations, and if not enough then interpolate\n",
        "        if len(self.data_tmp.dropna()) >= min_obs:\n",
        "            inpt_pre_train = self.data_tmp.dropna().values\n",
        "            self.autoencoder.compile(optimizer=self.optimizer, loss='mse')\n",
        "        else:\n",
        "            self.build_inputs()\n",
        "            inpt_pre_train = self.data_tmp.dropna().values\n",
        "            self.autoencoder.compile(optimizer=self.optimizer, loss=mse_missing)\n",
        "        # build output\n",
        "        oupt_pre_train = self.data_tmp.dropna()[self.data.columns].values\n",
        "        # fit (pre-train) autoencoder\n",
        "        self.autoencoder.fit(inpt_pre_train, oupt_pre_train, epochs=self.epoch * mult_epoch_pre,\n",
        "                             batch_size=self.batch_size,\n",
        "                             verbose=0)\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"\"\"\n",
        "        Method to train a Deep Dynamic Factor Model (see Algorithm 1 from the paper.)\n",
        "        Returns:\n",
        "            None, it updates attributes.\n",
        "        \"\"\"\n",
        "        # re-compile the autoencoder to re-init the optimizer and possibly change the objective\n",
        "        self.autoencoder.compile(optimizer=self.optimizer, loss=mse_missing)\n",
        "        # construct initial input data\n",
        "        self.build_inputs()\n",
        "        # make prediction\n",
        "        prediction_iter = self.autoencoder.predict(self.data_tmp.values)\n",
        "        # update missings\n",
        "        self.data_mod_only_miss.values[self.lags_input:][self.bool_miss] = prediction_iter[self.bool_miss]\n",
        "        # get idio\n",
        "        self.eps = self.data_tmp[self.data.columns].values - prediction_iter\n",
        "        # init counters\n",
        "        iter = 0\n",
        "        not_converged = True\n",
        "        loss_now = None\n",
        "        # start MCMC\n",
        "        while not_converged and iter < self.max_iter:\n",
        "            # get idio distr\n",
        "            phi, mu_eps, std_eps = get_idio(self.eps, self.bool_no_miss)\n",
        "            # subtract conditional AR-idio mean from x\n",
        "            self.data_mod[self.lags_input + 1:] = self.data_mod_only_miss[self.lags_input + 1:] - self.eps[:-1, :] @ phi\n",
        "            # for first observations set to 0 the idio\n",
        "            self.data_mod[:self.lags_input + 1] = self.data_mod_only_miss[:self.lags_input + 1]\n",
        "            # gen data_tmp from filtered inputs (self.data_mod above)\n",
        "            self.build_inputs()\n",
        "            # gen MC samples for idio (dims = Sim x T x D)\n",
        "            eps_draws = self.rng.multivariate_normal(mu_eps, np.diag(std_eps), (self.epoch, self.data_tmp.shape[0]))\n",
        "            # init noisy inputs (dims = Sim x T x D_with_lags)\n",
        "            x_sim_den = np.zeros((eps_draws.shape[0], eps_draws.shape[1], eps_draws.shape[2] * (self.lags_input + 1)))\n",
        "            # loop over them (MC step)\n",
        "            for i in range(self.epoch):\n",
        "                x_sim_den[i, :, :] = self.data_tmp.copy()\n",
        "                # corrupt input data, only current observations\n",
        "                x_sim_den[i, :, :eps_draws[i, :, :].shape[1]] = x_sim_den[i, :,\n",
        "                                                                :eps_draws[i, :, :].shape[1]] - eps_draws[i, :, :]\n",
        "                # fit autoencoder\n",
        "                self.autoencoder.fit(x_sim_den[i, :, :], self.z_actual, epochs=1, batch_size=self.batch_size, verbose=0)\n",
        "            # update factors: average over all predictions from the MC samples\n",
        "            self.factors = np.array([self.encoder(x_sim_den[i, :, :]) for i in range(x_sim_den.shape[0])])\n",
        "            # check convergence\n",
        "            prediction_iter = np.mean(np.array([self.decoder(self.factors[i, :, :]) for i in range(self.factors.shape[0]\n",
        "                                                                                                   )]), axis=0)\n",
        "            if iter > 1:\n",
        "                delta, self.loss_now = convergence_checker(prediction_prev_iter, prediction_iter, self.z_actual)\n",
        "                #loss_now = loss_now\n",
        "                if iter % self.disp == 0:\n",
        "                    return self.loss_now\n",
        "                    print(f'@Info: iteration: {iter} - new loss: {self.loss_now} - delta: {delta}')\n",
        "                if delta < self.tolerance:\n",
        "                    not_converged = False\n",
        "                    print(f'@Info: Convergence achieved in {iter} iterations - new loss: {self.loss_now} - delta: {delta} < {self.tolerance}')\n",
        "            # store previous prediction to monitor convergence\n",
        "            prediction_prev_iter = prediction_iter.copy()\n",
        "            # update missings\n",
        "            self.data_mod_only_miss.values[self.lags_input:][self.bool_miss] = prediction_iter[self.bool_miss]\n",
        "            # update idio\n",
        "            self.eps = self.data_mod_only_miss.values[self.lags_input:] - prediction_iter\n",
        "            iter += 1\n",
        "        if not_converged:\n",
        "            print(\"@Info: Convergence not achieved within the maximum number of iteration!\")\n",
        "\n",
        "    def build_state_space(self) -> None:\n",
        "        \"\"\"\n",
        "        Method to build the state space model from the autoencoder.\n",
        "            measurement: z_t = H x_t + v_t; v_t ∼ N(0, R)\n",
        "            transition: x_t = F x_t-1 + w_t; w_t ∼ N(0, Q)\n",
        "        Returns:\n",
        "            None, it updates the class attributes.\n",
        "        \"\"\"\n",
        "        # extract common factors\n",
        "        f_t = np.mean(self.factors, axis=0)\n",
        "        # idio components\n",
        "        eps_t = self.eps\n",
        "        # get params from decoder (measurement equation)\n",
        "        bs, H = convert_decoder_to_numpy(self.decoder, self.use_bias, self.factor_oder,\n",
        "                                         structure_decoder=self.structure_decoder)\n",
        "        # modify mean with the bias term\n",
        "        self.mean_z = self.mean_z + bs * self.sigma_z\n",
        "        # get transition equation params\n",
        "        F, Q, mu_0, sigma_0, x_t = get_transition_params(f_t, eps_t, factor_oder=self.factor_oder,\n",
        "                                                         bool_no_miss=self.bool_no_miss)\n",
        "        # insert in dictionary\n",
        "        self.state_space_dict[\"transition\"] = dict()\n",
        "        self.state_space_dict[\"transition\"][\"F\"] = F\n",
        "        self.state_space_dict[\"transition\"][\"Q\"] = Q\n",
        "        self.state_space_dict[\"transition\"][\"mu_0\"] = mu_0\n",
        "        self.state_space_dict[\"transition\"][\"Σ_0\"] = sigma_0\n",
        "        self.latents[\"ae_states\"] = x_t\n",
        "        # we set this to a small number, but we could cross-validate to control the signal-to-noise ratio\n",
        "        R = np.eye(eps_t.shape[1]) * 1e-15\n",
        "        # H = None\n",
        "        self.state_space_dict[\"measurement\"] = dict()\n",
        "        self.state_space_dict[\"measurement\"][\"H\"] = H\n",
        "        self.state_space_dict[\"measurement\"][\"R\"] = R\n",
        "        self.state_space = StateSpace(self.mean_z, self.sigma_z,\n",
        "                                      self.state_space_dict[\"transition\"], self.state_space_dict[\"measurement\"],\n",
        "                                      filter_type=self.filter_type)\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Method to fit the Deep Dynamic Factor Model.\n",
        "        Returns:\n",
        "            None, it updates the class attributes.\n",
        "        \"\"\"\n",
        "        self.build_model()\n",
        "        self.pre_train()\n",
        "        self.train()\n",
        "        self.build_state_space()\n",
        "        # get filtered factors\n",
        "        self.latents[\"filtered\"], self.latents[\"sigma_kf\"] = self.filter(self.data.values)\n",
        "        self.factors_filtered = self.latents[\"filtered\"][:, 1:self.structure_encoder[-1] + 1]\n",
        "    def get_last_state(self):\n",
        "        \"\"\"\n",
        "        Retrieves the last state and its variance-covariance matrix from the fitted model.\n",
        "        Returns:\n",
        "        tuple: A tuple containing the last state and its variance-covariance matrix.\n",
        "        \"\"\"\n",
        "        last_state = self.latents[\"filtered\"][-1]\n",
        "        last_state_var_cov_matrix = self.latents[\"sigma_kf\"][-1]\n",
        "        return last_state, last_state_var_cov_matrix\n",
        "\n",
        "\n",
        "    def filter(self, z_t: np.ndarray, standardize: bool = False) -> Tuple[\n",
        "        np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Method to carry out the filtering in state-space.\n",
        "        Args:\n",
        "            z_t: observable realised values\n",
        "            standardize: whether to standardize the inputs or not\n",
        "\n",
        "        Returns:\n",
        "            filtered states and variance-covariance matrix\n",
        "        \"\"\"\n",
        "        return self.state_space.filter(z_t, standardize=standardize)\n",
        "\n",
        "\n",
        "    def predict(self, x_hat_start: np.ndarray, sigma_x_hat_start: np.ndarray, steps_ahead: int = 1) -> dict:\n",
        "        \"\"\"\n",
        "        Method to carry out the prediction in state-space.\n",
        "        Args:\n",
        "            x_hat_start: starting values for the state mean\n",
        "            sigma_x_hat_start: starting values for the state variance covariance matrix\n",
        "            steps_ahead: number of steps ahead\n",
        "\n",
        "        Returns:\n",
        "            A dictionary with predicted states and measurement mean and variances.\n",
        "        \"\"\"\n",
        "        return self.state_space.predict(x_hat_start, sigma_x_hat_start, steps_ahead=steps_ahead)\n",
        "\n",
        "    def predict_observations(self, x_hat_start: np.ndarray, sigma_x_hat_start: np.ndarray, steps_ahead: int = 1) -> np.ndarray:\n",
        "      \"\"\"\n",
        "      Predicts future observations (y_{t+k}) using the deep dynamic factor model.\n",
        "      Args:\n",
        "        x_hat_start: Starting values for the state mean.\n",
        "        sigma_x_hat_start: Starting values for the state variance covariance matrix.\n",
        "        steps_ahead: Number of steps ahead.\n",
        "      Returns:\n",
        "        Predicted future observations (y_{t+k}).\n",
        "      \"\"\"\n",
        "      # Predict future states (f_{t+k})\n",
        "      future_states = self.predict(x_hat_start, sigma_x_hat_start, steps_ahead)['states']\n",
        "      # Predict future observations (y_{t+k})\n",
        "      future_observations = self.state_space.predict_measurement(future_states)\n",
        "      return future_observations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ztY2r-rkleh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ddfm6.state_space_dict[\"transition\"][\"Σ_0\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T5kEg_TN--s",
        "outputId": "b4a42dc2-34a4-4b0f-f4ce-a7592751d87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124, 124)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para 7 factores:"
      ],
      "metadata": {
        "id": "u7zhGQWi791u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_true=7\n",
        "structure_encoders = [\n",
        "    (r_true * 4, r_true * 2, r_true),\n",
        "    (r_true * 6, r_true * 4, r_true),\n",
        "    (r_true * 12, r_true * 6, r_true)\n",
        "]\n",
        "\n",
        "lags_inputs = list(range(2))\n",
        "\n",
        "model_info = []\n",
        "\n",
        "# Iterate over both True and False values for use_bias\n",
        "for use_bias_setting in [True, False]:\n",
        "    # Iterate over each structure_encoder configuration\n",
        "    for structure_encoder in structure_encoders:\n",
        "        # Iterate over each lag value\n",
        "        for lags_input in lags_inputs:\n",
        "            # Initialize the DDFM with the current configuration and use_bias setting\n",
        "            ddfm = DDFM(df_train_idx, lags_input=lags_input, structure_encoder=structure_encoder,\n",
        "                        optimizer='Adam', factor_oder=1, use_bias=use_bias_setting, link='tanh',\n",
        "                        epochs=100, max_iter=1000)\n",
        "\n",
        "            # Fit the model\n",
        "            ddfm.fit()\n",
        "\n",
        "            # Store the model, its configuration, and final loss\n",
        "            final_loss = ddfm.loss_now\n",
        "            model_info.append((ddfm, structure_encoder, lags_input, use_bias_setting, final_loss))\n",
        "\n",
        "# Print the information for each model\n",
        "for model, encoder_config, lag, use_bias_setting, final_loss in model_info:\n",
        "    print(f\"Model with encoder {encoder_config}, lag {lag}, use_bias {use_bias_setting} - Final Loss: {final_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUSPVcj3RGje",
        "outputId": "d72705ac-ce59-4ef9-cdde-f1065f98198e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 3ms/step\n",
            "@Info: Convergence achieved in 8 iterations - new loss: 0.568943095022181 - delta: 0.000360916890050795 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 8 iterations - new loss: 0.5632790321861864 - delta: 2.0773473356622294e-05 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.5676663599891031 - delta: 0.00027047013742516676 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 8 iterations - new loss: 0.5611486675911035 - delta: 0.00042446792035540976 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 3ms/step\n",
            "@Info: Convergence achieved in 8 iterations - new loss: 0.5654334640322526 - delta: 5.01459603299358e-05 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5604593507499629 - delta: 0.00042653699984882167 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.5717539216722599 - delta: 0.00026740105581168645 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 8 iterations - new loss: 0.5629582300256385 - delta: 0.00031287091434474497 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 3ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.567330625303696 - delta: 0.000331688450235145 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5613694095081316 - delta: 0.00021297932314083958 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5656696485174427 - delta: 7.172122357466804e-05 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5601520308495807 - delta: 0.0004424188786539138 < 0.0005\n",
            "Model with encoder (28, 14, 7), lag 0, use_bias True - Final Loss: 0.568943095022181\n",
            "Model with encoder (28, 14, 7), lag 1, use_bias True - Final Loss: 0.5632790321861864\n",
            "Model with encoder (42, 28, 7), lag 0, use_bias True - Final Loss: 0.5676663599891031\n",
            "Model with encoder (42, 28, 7), lag 1, use_bias True - Final Loss: 0.5611486675911035\n",
            "Model with encoder (84, 42, 7), lag 0, use_bias True - Final Loss: 0.5654334640322526\n",
            "Model with encoder (84, 42, 7), lag 1, use_bias True - Final Loss: 0.5604593507499629\n",
            "Model with encoder (28, 14, 7), lag 0, use_bias False - Final Loss: 0.5717539216722599\n",
            "Model with encoder (28, 14, 7), lag 1, use_bias False - Final Loss: 0.5629582300256385\n",
            "Model with encoder (42, 28, 7), lag 0, use_bias False - Final Loss: 0.567330625303696\n",
            "Model with encoder (42, 28, 7), lag 1, use_bias False - Final Loss: 0.5613694095081316\n",
            "Model with encoder (84, 42, 7), lag 0, use_bias False - Final Loss: 0.5656696485174427\n",
            "Model with encoder (84, 42, 7), lag 1, use_bias False - Final Loss: 0.5601520308495807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to store the minimum loss and associated configuration.\n",
        "min_loss = float('inf')\n",
        "min_loss_config = None\n",
        "\n",
        "# Iterate over the stored models to find the one with the minimum loss.\n",
        "for model, encoder_config, lag, use_bias_setting, final_loss in model_info:\n",
        "    if final_loss < min_loss:\n",
        "        min_loss = final_loss\n",
        "        min_loss_config = (encoder_config, lag, use_bias_setting)\n",
        "\n",
        "# Print the configuration with the minimum loss.\n",
        "if min_loss_config is not None:\n",
        "    print(f\"Minimum Loss: {min_loss} with encoder {min_loss_config[0]}, lag {min_loss_config[1]}, and use_bias {min_loss_config[2]}\")\n",
        "else:\n",
        "    print(\"No models found or no valid loss values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS4IoSmbWryF",
        "outputId": "be72cf49-d922-4134-c0c9-c42039970c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Loss: 0.5601520308495807 with encoder (84, 42, 7), lag 1, and use_bias False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm7 = DDFM(df_train_idx, structure_encoder=(84, 42, 7), lags_input=1, factor_oder=1,\n",
        "                             use_bias=False, link='tanh', max_iter=1000)\n",
        "ddfm7.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANcBVSyXbUOQ",
        "outputId": "0bb7bc79-2811-4849-d542-dc57ff31d244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 4ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5601794409845514 - delta: 0.00043359827501088005 < 0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_state, last_state_var_cov_matrix = ddfm7.get_last_state()"
      ],
      "metadata": {
        "id": "3DW8Mcs_lBr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat=ddfm7.state_space_dict[\"transition\"][\"F\"]@x_hat_start\n",
        "f_hat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7cyKpz2mxR5",
        "outputId": "ec0ca8a5-0e42-47ee-f336-5d1dcbb58186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_ahead =12  # for example, predict 5 steps ahead\n",
        "predictions7 = ddfm7.predict(last_state, last_state_var_cov_matrix, steps_ahead)\n",
        "#predictions7['states'].shape\n",
        "y_t_k_7=ddfm7.predict_observations(last_state,last_state_var_cov_matrix , steps_ahead)\n",
        "df_test_first_12_rows = data_test.iloc[:12, :]\n",
        "test_array12 = df_test_first_12_rows.to_numpy()\n",
        "mse_row12=np.mean((test_array12 - y_t_k_7)**2, axis=1)\n",
        "mse_12=np.mean(mse_row12)\n",
        "mae_12 = np.mean(np.abs(test_array12 - y_t_k_7))\n",
        "rmsfe_12 = np.sqrt(np.mean((test_array12 - y_t_k_7) ** 2))\n",
        "print(\"Mean Squared Error:\", mse_12)\n",
        "print(\"Mean Absolute Error:\", mae_12)\n",
        "print(\"Root Mean Squared Forecast Error:\", rmsfe_12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hNvoapSS9Aw",
        "outputId": "3e4f5ab3-d157-49c4-e5e0-378aff97455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3.2279855049036486\n",
            "Mean Absolute Error: 1.2606368648611543\n",
            "Root Mean Squared Forecast Error: 1.7966595406207735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_ahead = df_test_idx.shape[0]  # for example, predict 5 steps ahead\n",
        "predictions7 = ddfm7.predict(last_state, last_state_var_cov_matrix, steps_ahead)\n",
        "#predictions7['states'].shape\n",
        "y_t_k_7=ddfm7.predict_observations(last_state, last_state_var_cov_matrix, steps_ahead)\n",
        "#df_test_first_12_rows = df_test_idx.iloc[:12, :]\n",
        "test_array = data_test.to_numpy()\n",
        "mse_row=np.mean((test_array - y_t_k_7)**2, axis=1)\n",
        "mse_145=np.mean(mse_row)\n",
        "mae_145 = np.mean(np.abs(test_array - y_t_k_7))\n",
        "rmsfe_145 = np.sqrt(np.mean((test_array - y_t_k_7) ** 2))\n",
        "print(\"Mean Squared Error:\", mse_145)\n",
        "print(\"Mean Absolute Error:\", mae_145)\n",
        "print(\"Root Mean Squared Forecast Error:\", rmsfe_145)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YlQFFuIyjzO",
        "outputId": "6a4b2d44-df48-46ab-f48d-5c62f77cc35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.9740722982081937\n",
            "Mean Absolute Error: 0.6888614785125942\n",
            "Root Mean Squared Forecast Error: 0.9869510110477591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para 6 factores:"
      ],
      "metadata": {
        "id": "ZSNwENQ1XKii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = 6\n",
        "structure_encoders = [(r * 6, r * 4, r * 2, r),\n",
        "                      (r * 12, r * 6, r * 4, r)]\n",
        "\n",
        "lags_inputs = list(range(2))\n",
        "\n",
        "model_info = []\n",
        "\n",
        "# Iterate over both True and False values for use_bias\n",
        "for use_bias_setting in [True, False]:\n",
        "    # Iterate over each structure_encoder configuration\n",
        "    for structure_encoder in structure_encoders:\n",
        "        # Iterate over each lag value\n",
        "        for lags_input in lags_inputs:\n",
        "            # Initialize the DDFM with the current configuration and use_bias setting\n",
        "            ddfm = DDFM(df_train_idx, lags_input=lags_input, structure_encoder=structure_encoder,\n",
        "                        optimizer='Adam', factor_oder=1, use_bias=use_bias_setting, link='tanh',\n",
        "                        epochs=100, max_iter=1000)\n",
        "\n",
        "            # Fit the model\n",
        "            ddfm.fit()\n",
        "\n",
        "            # Store the model, its configuration, and final loss\n",
        "            final_loss = ddfm.loss_now\n",
        "            model_info.append((ddfm, structure_encoder, lags_input, use_bias_setting, final_loss))\n",
        "\n",
        "# Print the information for each model\n",
        "for model, encoder_config, lag, use_bias_setting, final_loss in model_info:\n",
        "    print(f\"Model with encoder {encoder_config}, lag {lag}, use_bias {use_bias_setting} - Final Loss: {final_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FumFiuWOoRmJ",
        "outputId": "1b433c2a-c0d2-4b91-b35d-df6fecb41081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 4 iterations - new loss: 0.6044490276205244 - delta: 0.0003656000110053137 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 6 iterations - new loss: 0.5924190376465651 - delta: 0.00047010963246637725 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 4 iterations - new loss: 0.5991136372167796 - delta: 0.00018932438242943 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 5 iterations - new loss: 0.5905504150709575 - delta: 0.00038853532190897665 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.6019140286258788 - delta: 0.0003068920457274224 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 3 iterations - new loss: 0.5962017297374651 - delta: 0.0002724940696371986 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 4 iterations - new loss: 0.5990049492544678 - delta: 0.0002645030239152514 < 0.0005\n",
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.5898424215737922 - delta: 0.0003419668455476391 < 0.0005\n",
            "Model with encoder (36, 24, 12, 6), lag 0, use_bias True - Final Loss: 0.6044490276205244\n",
            "Model with encoder (36, 24, 12, 6), lag 1, use_bias True - Final Loss: 0.5924190376465651\n",
            "Model with encoder (72, 36, 24, 6), lag 0, use_bias True - Final Loss: 0.5991136372167796\n",
            "Model with encoder (72, 36, 24, 6), lag 1, use_bias True - Final Loss: 0.5905504150709575\n",
            "Model with encoder (36, 24, 12, 6), lag 0, use_bias False - Final Loss: 0.6019140286258788\n",
            "Model with encoder (36, 24, 12, 6), lag 1, use_bias False - Final Loss: 0.5962017297374651\n",
            "Model with encoder (72, 36, 24, 6), lag 0, use_bias False - Final Loss: 0.5990049492544678\n",
            "Model with encoder (72, 36, 24, 6), lag 1, use_bias False - Final Loss: 0.5898424215737922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to store the minimum loss and associated configuration.\n",
        "min_loss = float('inf')\n",
        "min_loss_config = None\n",
        "\n",
        "# Iterate over the stored models to find the one with the minimum loss.\n",
        "for model, encoder_config, lag, use_bias_setting, final_loss in model_info:\n",
        "    if final_loss < min_loss:\n",
        "        min_loss = final_loss\n",
        "        min_loss_config = (encoder_config, lag, use_bias_setting)\n",
        "\n",
        "# Print the configuration with the minimum loss.\n",
        "if min_loss_config is not None:\n",
        "    print(f\"Minimum Loss: {min_loss} with encoder {min_loss_config[0]}, lag {min_loss_config[1]}, and use_bias {min_loss_config[2]}\")\n",
        "else:\n",
        "    print(\"No models found or no valid loss values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ypLVGHMo69h",
        "outputId": "f23d85ac-8d2d-469f-a856-6da2b01aa9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Loss: 0.5898424215737922 with encoder (72, 36, 24, 6), lag 1, and use_bias False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddfm6 = DDFM(df_train_idx, structure_encoder=(72, 36, 6), lags_input=1, factor_oder=1,\n",
        "                             use_bias=False, link='tanh', max_iter=1000)\n",
        "ddfm6.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBWbuZwx_6MV",
        "outputId": "f6ba4963-38d3-4df9-ab20-64975c1b6319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@Info - Note: Sorting data.\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "@Info: Convergence achieved in 7 iterations - new loss: 0.5897091840144462 - delta: 0.00026435753202212536 < 0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_state, last_state_var_cov_matrix = ddfm6.get_last_state()"
      ],
      "metadata": {
        "id": "g_jciHskfia-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCMFDVPnfk2H",
        "outputId": "1347d379-e440-471a-ab90-4a060dcff11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124,)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_ahead = df_test_idx.shape[0]  # for example, predict 5 steps ahead\n",
        "predictions6 = ddfm6.predict(last_state, last_state_var_cov_matrix, steps_ahead)\n",
        "#predictions7['states'].shape\n",
        "y_t_k_6=ddfm6.predict_observations(x_hat_start6, sigma_x_hat_start6, steps_ahead)\n",
        "#df_test_first_12_rows = df_test_idx.iloc[:12, :]\n",
        "test_array = data_test.to_numpy()\n",
        "mse_row=np.mean((test_array - y_t_k_6)**2, axis=1)\n",
        "mse_145=np.mean(mse_row)\n",
        "mae_145 = np.mean(np.abs(test_array - y_t_k_6))\n",
        "rmsfe_145 = np.sqrt(np.mean((test_array - y_t_k_6) ** 2))\n",
        "print(\"Mean Squared Error:\", mse_145)\n",
        "print(\"Mean Absolute Error:\", mae_145)\n",
        "print(\"Root Mean Squared Forecast Error:\", rmsfe_145)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJefrAGCMhk",
        "outputId": "fc110b89-0213-43af-cd3e-808e579c1085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.0300044974802698\n",
            "Mean Absolute Error: 0.703399646960847\n",
            "Root Mean Squared Forecast Error: 1.014891372256297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#n = ddfm.state_space.F.shape[0]\n",
        "#x_hat_start = np.zeros((1, n))\n",
        "#sigma_x_hat_start = np.eye(ddfm.state_space.F.shape[0])\n",
        "#x_hat_start.shape"
      ],
      "metadata": {
        "id": "7KYikWg204_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dir(ddfm)"
      ],
      "metadata": {
        "id": "RNsajVuqvPNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat=ddfm6.state_space_dict[\"transition\"][\"F\"]@x_hat_start6\n",
        "f_hat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwwaphuXZnk_",
        "outputId": "f70c8a23-19c9-4489-c191-37869e41fdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### factores filtrados"
      ],
      "metadata": {
        "id": "ownemPmS75og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ff6=ddfm6.factors_filtered\n",
        "ff6.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjdS7Pws2mDd",
        "outputId": "d6c2692b-064d-4e71-f79c-9657412688a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(577, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat_ddfm_idx6 = pd.DataFrame(ff6, columns=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"])"
      ],
      "metadata": {
        "id": "wkrZBYdr3rQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat_ddfm_idx6.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JKcP-ci6j1nx",
        "outputId": "1b736073-9c12-4dab-c926-e8f55df6d02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         f1        f2        f3        f4        f5        f6\n",
              "0 -0.512616  0.008194  0.166183  0.624644  0.487667 -0.904841\n",
              "1  0.217684  0.307360 -0.116110  0.154630 -0.606569  0.121623\n",
              "2 -0.393536  0.412020  0.033630 -0.017483 -0.588406  0.550374\n",
              "3  0.082301 -0.095549  0.023001 -0.004909 -0.395127  0.356847\n",
              "4 -0.170490  0.375945  0.173957 -0.112834  0.075884  0.209188"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-196db193-26c4-4330-91e5-0f4867f0b52e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.512616</td>\n",
              "      <td>0.008194</td>\n",
              "      <td>0.166183</td>\n",
              "      <td>0.624644</td>\n",
              "      <td>0.487667</td>\n",
              "      <td>-0.904841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.217684</td>\n",
              "      <td>0.307360</td>\n",
              "      <td>-0.116110</td>\n",
              "      <td>0.154630</td>\n",
              "      <td>-0.606569</td>\n",
              "      <td>0.121623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.393536</td>\n",
              "      <td>0.412020</td>\n",
              "      <td>0.033630</td>\n",
              "      <td>-0.017483</td>\n",
              "      <td>-0.588406</td>\n",
              "      <td>0.550374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.082301</td>\n",
              "      <td>-0.095549</td>\n",
              "      <td>0.023001</td>\n",
              "      <td>-0.004909</td>\n",
              "      <td>-0.395127</td>\n",
              "      <td>0.356847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.170490</td>\n",
              "      <td>0.375945</td>\n",
              "      <td>0.173957</td>\n",
              "      <td>-0.112834</td>\n",
              "      <td>0.075884</td>\n",
              "      <td>0.209188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-196db193-26c4-4330-91e5-0f4867f0b52e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-196db193-26c4-4330-91e5-0f4867f0b52e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-196db193-26c4-4330-91e5-0f4867f0b52e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69c66a93-76af-462e-ab9d-11cb3194a22b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69c66a93-76af-462e-ab9d-11cb3194a22b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69c66a93-76af-462e-ab9d-11cb3194a22b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat_ddfm_idx6.index = df_train_idx.index\n",
        "f_hat_ddfm6=f_hat_ddfm_idx6.reset_index()"
      ],
      "metadata": {
        "id": "Z1bw1Epy6Pje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_hat_ddfm6.to_csv('/content/drive/MyDrive/D2FM/f_hat_ddfm6.csv', index=False)"
      ],
      "metadata": {
        "id": "5NLMaDQR4Wqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}